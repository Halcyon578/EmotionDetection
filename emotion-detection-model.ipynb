{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ****Emotion Detection Model****","metadata":{}},{"cell_type":"markdown","source":"This model detects the seven basic emotions defined by Paul Ekman: happiness, sadness, anger, fear, disgust, surprise, and neutrality — using a Convolutional Neural Network (CNN). It was trained on a combination of facial expression datasets to improve generalization and accuracy. ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"> # Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.applications import ResNet50V2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> # Preparing Data","metadata":{}},{"cell_type":"code","source":"# Function to count classes in the dataset\ndef Classes_Count(path, name):\n    Classes_Dict = {}\n    for Class in os.listdir(path):\n        Full_Path = os.path.join(path, Class)\n        Classes_Dict[Class] = len(os.listdir(Full_Path))\n    df = pd.DataFrame(Classes_Dict, index=[name])\n    return df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data paths\ntrain_dir = '/kaggle/input/combined/combined/train'\ntest_dir = '/kaggle/input/combined/combined/test'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count classes in train and test datasets\nTrain_Count = Classes_Count(train_dir, 'Train').transpose().sort_values(by=\"Train\", ascending=False)\nTest_Count = Classes_Count(test_dir, 'Test').transpose().sort_values(by=\"Test\", ascending=False)\npd.concat([Train_Count, Test_Count], axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image parameters\nimg_shape = 224\nbatch_size = 64","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> # Image Data Generator","metadata":{}},{"cell_type":"code","source":"# ImageDataGenerator for train and test data\nemotion_classes = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n\ntrain_preprocessor = ImageDataGenerator(\n    rescale=1 / 255.,\n    rotation_range=10,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest',\n)\n\ntest_preprocessor = ImageDataGenerator(rescale=1 / 255.)\n\ntrain_data = train_preprocessor.flow_from_directory(\n    train_dir,\n    class_mode=\"categorical\",\n    classes=emotion_classes,\n    target_size=(img_shape, img_shape),\n    color_mode='rgb',\n    shuffle=True,\n    batch_size=batch_size,\n    subset='training',\n)\ntest_data = test_preprocessor.flow_from_directory(\n    test_dir,\n    class_mode=\"categorical\",\n    classes=emotion_classes,\n    target_size=(img_shape, img_shape),\n    color_mode=\"rgb\",\n    shuffle=False,\n    batch_size=batch_size,\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> # Model ","metadata":{}},{"cell_type":"code","source":"# Load pre-trained ResNet50V2 model\nResNet50V2_base = ResNet50V2(input_shape=(img_shape, img_shape, 3),\n                             include_top=False,\n                             weights='imagenet'\n                             )\n\n# Freeze all layers except last 50\nResNet50V2_base.trainable = True\nfor layer in ResNet50V2_base.layers[:-50]:\n    layer.trainable = False\n\n# Custom model using ResNet50V2\ndef Create_Custom_ResNet50V2_Model():\n    model = Sequential([\n        ResNet50V2_base,\n        Dropout(0.25),\n        BatchNormalization(),\n        Flatten(),\n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(7, activation='softmax')\n    ])\n    return model\n\nResNet50V2_Model = Create_Custom_ResNet50V2_Model()\nResNet50V2_Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> # Callbacks and training","metadata":{}},{"cell_type":"code","source":"# Callbacks\ncheckpoint_path = \"ResNet50V2_Model_Checkpoint.keras\"\nCheckpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\nEarly_Stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1)\nReducing_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n\ncallbacks = [Early_Stopping, Reducing_LR]\n\nsteps_per_epoch = train_data.n // train_data.batch_size\nvalidation_steps = test_data.n // test_data.batch_size\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ResNet50V2_history = ResNet50V2_Model.fit(train_data, validation_data=test_data, epochs=30, batch_size=batch_size,\n                                           callbacks=callbacks, steps_per_epoch=steps_per_epoch,\n                                           validation_steps=validation_steps)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> # Results","metadata":{}},{"cell_type":"code","source":"ResNet50V2_Score = ResNet50V2_Model.evaluate(test_data)\nprint(\"Test Loss: {:.5f}\".format(ResNet50V2_Score[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(ResNet50V2_Score[1] * 100))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to plot training curves\ndef plot_curves(history):\n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n    accuracy = history.history[\"accuracy\"]\n    val_accuracy = history.history[\"val_accuracy\"]\n    epochs = range(len(history.history[\"loss\"]))\n\n    plt.figure(figsize=(15, 5))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label=\"training_loss\")\n    plt.plot(epochs, val_loss, label=\"val_loss\")\n    plt.title(\"Loss\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n    plt.title(\"Accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\nplot_curves(ResNet50V2_history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ResNet50V2_Model.save('resnet50v2_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ResNet50V2_Model.save(\"resnet50v2_model.keras\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ny_true = test_data.classes\ny_pred_probs = ResNet50V2_Model.predict(test_data, verbose=1)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt=\"d\", \n            xticklabels=emotion_classes, \n            yticklabels=emotion_classes, cmap=\"Blues\")\nplt.ylabel('Clase real')\nplt.xlabel('Clase predicha')\nplt.title('Matriz de Confusión')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nreport = classification_report(y_true, y_pred, target_names=emotion_classes, digits=4)\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\n\ny_true_bin = label_binarize(y_true, classes=range(len(emotion_classes)))\n\nplt.figure(figsize=(10,8))\nfor i, emotion in enumerate(emotion_classes):\n    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n    auc_score = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f\"{emotion} (AUC = {auc_score:.2f})\")\n\nplt.plot([0,1],[0,1],'--', color='gray')\nplt.title('Curvas ROC por clase')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, average_precision_score\n\nplt.figure(figsize=(10,8))\nfor i, emotion in enumerate(emotion_classes):\n    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_probs[:, i])\n    ap_score = average_precision_score(y_true_bin[:, i], y_pred_probs[:, i])\n    plt.plot(recall, precision, label=f\"{emotion} (AP = {ap_score:.2f})\")\n\nplt.title('Curvas Precision-Recall por clase')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc='lower left')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\npred_max_probs = np.max(y_pred_probs, axis=1)\nplt.hist(pred_max_probs, bins=20)\nplt.title(\"Distribución de Probabilidades Máximas\")\nplt.xlabel(\"Probabilidad predicha más alta\")\nplt.ylabel(\"Número de muestras\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}